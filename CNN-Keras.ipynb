{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os, re\n",
    "import shutil\n",
    "import random\n",
    "import dill\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import skimage\n",
    "from skimage.io import imread, imsave\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import adam, sgd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metal296</td>\n",
       "      <td>/Users/loaner/Documents/github/trash-classifie...</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plastic391</td>\n",
       "      <td>/Users/loaner/Documents/github/trash-classifie...</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardboard233</td>\n",
       "      <td>/Users/loaner/Documents/github/trash-classifie...</td>\n",
       "      <td>cardboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardboard227</td>\n",
       "      <td>/Users/loaner/Documents/github/trash-classifie...</td>\n",
       "      <td>cardboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plastic385</td>\n",
       "      <td>/Users/loaner/Documents/github/trash-classifie...</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name                                               path      label\n",
       "0      metal296  /Users/loaner/Documents/github/trash-classifie...      metal\n",
       "1    plastic391  /Users/loaner/Documents/github/trash-classifie...    plastic\n",
       "2  cardboard233  /Users/loaner/Documents/github/trash-classifie...  cardboard\n",
       "3  cardboard227  /Users/loaner/Documents/github/trash-classifie...  cardboard\n",
       "4    plastic385  /Users/loaner/Documents/github/trash-classifie...    plastic"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create df\n",
    "img_path = os.path.join(os.getcwd(), \"data/raw_data/resize-mixed\")\n",
    "names = [f.split(\".\")[0] for f in os.listdir(img_path) if any(c.isdigit() for c in f)]\n",
    "labels = [re.sub(r'\\d+', '', name) for name in names]\n",
    "paths = [os.path.join(img_path, f+\".jpg\") for f in names]\n",
    "dict_df = pd.DataFrame(zip(names, paths, labels), columns=['name','path', 'label'], dtype=str)\n",
    "dict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image augmentation \n",
    "from skimage import transform\n",
    "def rotate(image_array: np.ndarray):\n",
    "    '''rotate image with a random degree (between left_degree and right_degree)'''\n",
    "    degree_limit = 30\n",
    "    rotate_degree = random.uniform(-degree_limit, degree_limit)\n",
    "    return transform.rotate(image_array, rotate_degree)*255\n",
    "\n",
    "def add_noise(image_array: np.ndarray):\n",
    "    '''add noise to image'''\n",
    "    return skimage.util.random_noise(image_array)*255\n",
    "\n",
    "def hor_flip(image_array: np.ndarray):\n",
    "    '''flipping pixels horizontally'''\n",
    "    return image_array[:, ::-1]\n",
    "\n",
    "def ver_flip(image_array: np.ndarray):\n",
    "    '''flipping pixels vertically'''\n",
    "    return image_array[::-1, :]\n",
    "\n",
    "transform_methods = [rotate, add_noise, hor_flip, ver_flip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_more_trash(target_num, base_file_paths, count_for_name):\n",
    "    num_transformed = 0\n",
    "    aug_img_df = pd.DataFrame(columns=dict_df.columns)\n",
    "    \n",
    "    base_folder = os.path.join('data/raw_data/resized', 'trash')\n",
    "    aug_img_path = 'data/raw_data/resize_split/train/trash'\n",
    "    aug_path = 'data/raw_data/aug_data'\n",
    "\n",
    "    # delete if aug folder already exists (re-aug for every training set)\n",
    "    if not os.path.exists(aug_path):\n",
    "        os.mkdir(aug_path)\n",
    "    else:\n",
    "        for f in os.listdir(aug_path):\n",
    "            os.remove(os.path.join(aug_path, f))\n",
    "    \n",
    "    while num_transformed <= target_num:\n",
    "        rand_path = random.choice(base_file_paths)\n",
    "        # base_img = dill.load(open(rand_path, 'rb'))\n",
    "        base_img = imread(rand_path)\n",
    "\n",
    "        new_img = transform_methods[random.randint(0,3)](base_img).astype(np.uint8)\n",
    "        num_transformed += 1\n",
    "        \n",
    "        new_img_name = \"trash{}\".format(str(count_for_name + num_transformed))\n",
    "        new_img_path = os.path.join(aug_path, new_img_name)\n",
    "        \n",
    "        aug_img_df = aug_img_df.append({\"name\":new_img_name, \"path\":new_img_path, \"label\": \"trash\"},ignore_index=True)\n",
    "        dill.dump(new_img, open(new_img_path, 'wb'))\n",
    "        imsave(os.path.join(aug_img_path, new_img_name+\".jpg\"),new_img)\n",
    "    return aug_img_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_aug(data_df, test_size):\n",
    "\n",
    "    X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(data_df, data_df['label'], \\\n",
    "                                                                    test_size=test_size)\n",
    "\n",
    "    # data augmentation prep\n",
    "    trash_base_df = X_train_df[X_train_df['label']=='trash']\n",
    "    trash_base_paths = trash_base_df['path'].tolist()\n",
    "    if len(trash_base_df[~trash_base_df['name'].str.contains('trash')])!=0:\n",
    "        raise \"label incorrect\"  # sanity check\n",
    "    else:\n",
    "        avg_numb = int((len(X_train_df)- len(trash_base_paths))/5)\n",
    "        trash_aug_numb = avg_numb - len(trash_base_paths)\n",
    "        aug_trash_df = create_more_trash(trash_aug_numb, trash_base_paths, 137)\n",
    "    \n",
    "    # load the augmented data into training set\n",
    "    X_train_df = X_train_df.append(aug_trash_df)\n",
    "    y_train_df = y_train_df.append(aug_trash_df['label'])\n",
    "    \n",
    "    # copy image to the resize_split folder\n",
    "    for index, row in X_train_df.iterrows():\n",
    "        dest_dir = os.path.join('data/raw_data/resize_split', 'train', row['label'])\n",
    "        shutil.copy(row['path'], dest_dir)\n",
    "        row['path'] = os.path.join(dest_dir, row['name']+\".jpg\")\n",
    "    \n",
    "    for index, row in X_test_df.iterrows():\n",
    "        dest_dir = os.path.join('data/raw_data/resize_split', 'test', row['label'])\n",
    "        shutil.copy(row['path'], dest_dir)\n",
    "        row['path'] = os.path.join(dest_dir, row['name']+\".jpg\")\n",
    "    \n",
    "    return X_train_df, X_test_df, y_train_df, y_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img_tensor(train_dir, test_dir, im_width, im_height, batch_size):\n",
    "    \n",
    "    im_gen = ImageDataGenerator(featurewise_center=False,\n",
    "                                 samplewise_center=False, \n",
    "                                 featurewise_std_normalization=False, \n",
    "                                 samplewise_std_normalization=False, \n",
    "                                 zca_whitening=False, \n",
    "                                 rotation_range=15, \n",
    "                                 width_shift_range=0.2, \n",
    "                                 height_shift_range=0.2, \n",
    "                                 horizontal_flip=True, \n",
    "                                 vertical_flip=True)\n",
    "\n",
    "\n",
    "    train_batch = im_gen.flow_from_directory(train_dir, target_size=(im_width, im_height), batch_size=batch_size)\n",
    "    test_batch = im_gen.flow_from_directory(test_dir,target_size=(im_width, im_height), batch_size=batch_size)\n",
    "    \n",
    "    return train_batch, test_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(im_w, im_h):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(im_w,im_h,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "#     model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "#     model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "#     model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "              \n",
    "    model.summary()\n",
    "              \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(model, img_path, img_w, img_h):\n",
    "    pic = imread(img_path)\n",
    "    pic = cv2.resize(pic, (img_w, img_h))\n",
    "    pic = np.expand_dims(pic, axis=0)\n",
    "    y_pred = model.predict_classes(pic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/raw_data/resize_split/train'\n",
    "test_path = 'data/raw_data/resize_split/test'\n",
    "\n",
    "img_w = 384\n",
    "img_h = 512\n",
    "num_classes = 6\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df, X_test_df, y_train_df, y_test_df = split_and_aug(dict_df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2287 images belonging to 6 classes.\n",
      "Found 506 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_tensor, test_tensor = generate_img_tensor(train_path, test_path, img_w, img_h, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 384, 512, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 192, 256, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 192, 256, 16)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 786432)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               402653696 \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 402,919,878\n",
      "Trainable params: 402,919,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = cnn_model(img_w, img_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('cnn_1', monitor='val_loss', verbose=1, save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=adam(lr=1.0e-4), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "34/45 [=====================>........] - ETA: 2:32 - loss: 1199.3241 - accuracy: 0.1700"
     ]
    }
   ],
   "source": [
    "model = model.fit_generator(train_tensor,  \n",
    "                            validation_data=test_tensor,\n",
    "                            steps_per_epoch=len(X_train_df) // batch_size,\n",
    "                            validation_steps=len(X_test_df) // batch_size,\n",
    "                            epochs=20, \n",
    "                            verbose=1, \n",
    "                            callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
